{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "15.2.1 Fundamentals of R Programming\n",
    "\n",
    "The two fundamental components to programming in R are creating data structures and using functions.\n",
    "\n",
    "Just like other object-oriented programming languages, R uses named data structures to store values and properties and uses functions to perform operations. The most straightforward R data structures are named values and vectors.\n",
    "\n",
    "Named values are exactly what they sound like—they are a value that has been given a name. We can think of named values as a variable that has been given a single value. \n",
    "\n",
    "Vectors are R's version of arrays, where a list of numbers are assigned a location and stored as a single data structure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To create our first data structure in R, we use an assignment statement. An assignment statement in R simply tells R the name of the object and assigns a value or data structure to that name.\n",
    "\n",
    "For example, say we want to create a named value x and assign it a value of 3, we would use this R command:\n",
    "\n",
    "> x <- 3\n",
    "\n",
    "The assignment operator (<-) tells R to assign whatever is right of the arrow to the name that is left of the arrow. In this case, we have given 3 the name of \"x.\" This is similar to assigning a variable in Python, except we use an assignment operator instead of the equals sign (=). Take a moment to run the command in your R console. This next image shows an RStudio session with the newly created \"x\" value:\n",
    "\n",
    "Did you notice that after you created a named value in the console, that named value appeared in your environmental pane? No matter what data structure you use, as you assign objects into your environment, they will appear in this pane. But what happens if you wanted to change that value to something new?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In R, all environment objects are mutable, which means they can be assigned and reassigned multiple times. If we want to assign a new value to x, we can do so using an assignment operator to assign a new value.\n",
    "\n",
    "And if we look back to our environment pane, our named value will have been reassigned and the changes reflected in real time:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The other simple data structure in R is the numeric vector. A numeric vector is an ordered list of numbers, very similar to a numeric list in Python. To create a numeric vector, we use the c()function. The c() function is short for concatenate, which means to link together. In R, we link together a comma-separated list of values into a single numerical vector. For instance, if we want to make a list of numbers from 0 to 9, we can pass the following command into the R console:\n",
    "\n",
    "> numlist <- c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\n",
    "\n",
    "The result of this command would assign the vector numlist into the environment:\n",
    "\n",
    "Notice that the environment pane shows the object name. If the object is not a named value, it will provide the data type and dimension. In this case, the numlistis a numeric (num) object with one row and 10 columns of values, as shown in the following image:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "R also supports a number of more advanced data structures such as matrices, data frames, and tibbles—all of which are variations of the same data frame concept:\n",
    "\n",
    "- A matrix can be thought of as a vector of vectors, where each value in the matrix is the same data type.\n",
    "\n",
    "- A data frame is very similar to a Pandas DataFrame where each column can be a different data type.\n",
    "\n",
    "- A tibble is a recent data object introduced by the tidyverse package in R and is an optimized data frame with extra   metadata and features. \n",
    "\n",
    "The most current libraries and packages in R use data frames or tibbles; however, older R packages and analysis scripts will still use matrix objects to perform specific functions or analyses.\n",
    "\n",
    "Now that we are familiar with assigning data structures and looking at environment objects, it's time to look at the other half of programming in R—using functions."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "15.2.2 Functions in R\n",
    "\n",
    "Functions behave similarly to methods (or even functions) in Python. In R, a function is used to perform a specific task and is denoted by parentheses. Functions can either be built-in, come from imported libraries, or be defined by the user.\n",
    "\n",
    "In this module, we have already used two built-in functions—the install.packages() function and the c() function. One required the name of the package to install and returned no value. The other could contain an unlimited number of arguments and would return a vector containing a list of equal size and order.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Regardless of where a function comes from, all R functions use the same basic syntax:\n",
    "\n",
    "function_name <- function(arg1, arg2=T, …){\n",
    "\n",
    "<BODY OF FUNCTION>\n",
    "\n",
    "return <RETURN VALUE>\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "There are four components of an R function:\n",
    "\n",
    "- The function name is the name of the function, which can be used in the R console to call the function itself.\n",
    "\n",
    "- Just like Python methods, R functions can have any number of required or optional arguments, depending on the design   of the function.\n",
    "\n",
    "- The function body includes data structures, if-statements, and other logical statements that define what the           function does.\n",
    "\n",
    "- The return statement is the last evaluated statement before returning the resulting value out of the function."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hello_world <- function(name, exclaim=TRUE){\n",
    "  if (exclaim == TRUE){\n",
    "    return(paste(\"hello\",name,\"!\"))\n",
    "  } else {\n",
    "    return(paste(\"hello\",name))\n",
    "  }\n",
    "}\n",
    "\n",
    "As we continue learning how to analyze and program using R, we'll encounter a wide variety of functions with different inputs, arguments, and outputs. Many of these functions, arguments, and outputs will be very similar to their Python counterparts.\n",
    "\n",
    "If at any point you are unsure what an R function does or what it needs to execute, you can always type ?<name of function> in the R console and it'll open the documentation in the Help pane. As we progress, we'll cover some RStudio shortcuts that help us easily navigate and implement obscure functions that we might need in specific situations.\n",
    "\n",
    "Now that we have learned about assigning data structures and using functions, it's time to bring these concepts together and write our very first RScript.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "15.2.3 Read and Write Using R\n",
    "\n",
    "Data analysis and visualization typically begin with reading in an external data source into our programming environment.\n",
    "\n",
    "There are built-in R functions to import the most common data formats, such as comma-separated values (CSV) and JavaScript Object Notation (JSON), as well as plenty of documentation and support online to import more advanced data structures.\n",
    "\n",
    "To read in a CSV file, we use R's read.csv() function. read.csv() has a few required arguments to work properly. To identify the required arguments, type the following code into the R console to look at the read.csv() documentation in the Help pane, listed under the subhead \"Usage\" in the image below:\n",
    "\n",
    "> ?read.csv()\n",
    "\n",
    "As we can see from the documentation, read.csv() is one of many read functions that all serve the same purpose: to read in tabular, character-delimited files and create a data frame object within our R environment.\n",
    "\n",
    "Depending on what delimiter (or value-separating character) is used, we can use read.csv()for comma-delimited files, read.delim() for tab-delimited files, or read.table() if we need to manually tell the function what delimiter is used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Although optional arguments are used to parse more complicated datasets, for our purposes, we'll only concentrate on the following arguments:\n",
    "\n",
    "file - is the local file path of the file we wish to read into our environment. Technically, it is the only required argument to run\n",
    "\n",
    "header - tells the function if a header is present in the CSV file. By default, this is TRUE.\n",
    "\n",
    "sep -  tells the function what the file uses as a delimiter. By default, this is a comma (“,”).\n",
    "\n",
    "check.names - will tell the function to check for spaces, punctuation, and other characters in the header and, if present, change them to periods (“.”). By default, this is TRUE.\n",
    "\n",
    "stringsAsFactors - tells the function that if the column is a string data type, to cast it as a factor. We’ll discuss factors later in the module, but most of the time we’ll want to manually create our factors. Therefore, we need to set this flag to FALSE."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now that we understand how to use the function, let's practice reading in a demo CSV file containing a hypothetical coworker's vehicle information.\n",
    "\n",
    "To practice reading in a CSV file, first download our sample CSV file:\n",
    "\n",
    "After demo.csv has downloaded, place the data file into your active working directory. Next, we'll use read.csv() in our source RScript pane to read in the demo file into our R environment. Type the following code:\n",
    "\n",
    "demo_table <- read.csv(file='demo.csv',check.names=F,stringsAsFactors = F)\n",
    "\n",
    "It isn't necessary to put a source file into our active working directory. If we ever want to read in a file from elsewhere on our computer, we would provide the full file path to our file argument.\n",
    "\n",
    "By writing our read statement in our RScript, we can always quickly create and recreate the data frame by sending our assignment function in the RScript to our R console."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "There are two ways to send RScript lines to our R console. We can either use the \"Run\" button in the top-right source pane or use the following shortcut:\n",
    "\n",
    "- Command + Enter (Mac)\n",
    "- CTRL + Enter (Windows)\n",
    "\n",
    "If we send our read.csv() function to the R console, we should see our demo_table created in our R environment without any errors\n",
    "\n",
    "Additionally, if we click on the demo_table in our environment pane, it will show us our data frame in a view-only tab in the source pane. Refer to the following image:\n",
    "\n",
    "This view-only data frame tab can be very helpful when we are trying to transform columns and rows of data in our RScripts, or when trying to select data to use in a visualization or statistical model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "But what if we want to bring in a dataset from an application programming interface (API) query?\n",
    "\n",
    "The JSON format is one of the most common data formats returned from a URL request. Although native JSON data can be easier to work with in Python, many data scientists still prefer to use R for their data analysis. To accommodate this need, R developers created the jsonlite library to read in JSON data structures and convert them to an R data frame. Because the jsonlite library was not built into R, we must import it into our R environment.\n",
    "\n",
    "To import a library into R, we'll use the library(package)function. Just like in Python, it's good practice to import any required libraries at the top of our RScript.\n",
    "\n",
    "Let's try loading in our installed jsonlite package using the library(jsonlite) function. Be sure to write the statement in your RScript and then send the statement to your R console (Command + Enter for Mac or CTRL + Enter for Windows)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Often you'll see conflicts or warnings when loading up packages in R, and usually these can be ignored. Only worry if your commands throw an error, which will print out in red text.\n",
    "\n",
    "If at any time your R console throws errors when trying to import a library, you can always try to reinstall the package using the install.packages() function.\n",
    "\n",
    "At this point, you may wish to save your R script by going to File, then Save. That way, you'll be able to open it later as you left it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now that we have successfully imported our jsonlite package, we can use the fromJSON() function to read in a JSON file into R.\n",
    "\n",
    "First, type the following code into the R console to look at the fromJSON() documentation in the Help pane:\n",
    "\n",
    "> ?fromJSON()\n",
    "\n",
    "As we can see, we only need to provide the txt argument to properly read in a JSON file into R because the other parameters have default values indicated with equations (e.g. simplifyVector=True). txt is the file path of the JSON file on our machine. Alternatively, we can provide the fromJSON() function a JSON URL directly. Now let's practice reading in our first JSON file."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First, download the sample JSON file containing used car data using the link below.\n",
    "\n",
    "Place the downloaded data file in your active working directory. Next, use fromJSON() in our source RScript pane to read in the used car data into our R environment, as follows:\n",
    "\n",
    "demo_table2 <- fromJSON(txt='demo.json')\n",
    "\n",
    "Once again, if we click the demo_table2 in our environment pane, it will show us our data frame in a view-only tab in the source pane:\n",
    "\n",
    "Now that we know how to create data structures and data frames in R, let's learn how to slice and sample our datasets."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "15.2.4 Select Data in R\n",
    "\n",
    "There are many ways to select and subset data in R, depending on what data structure is being used. When it comes to vectors, the easiest way to select data is using the bracket (\"[ ]\") notation. For example, if we have a numeric vector x with 10 values and want to select the third value, we would use the following statements:\n",
    "\n",
    "> x <- c(3, 3, 2, 2, 5, 5, 8, 8, 9)\n",
    "> x[3]\n",
    "\n",
    "Unlike Python, R's index starts at 1. So, the third element would be index = 3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "You can also use bracket notation to select data from two-dimensional data structures, such as matrices, data frames, and tibbles. For example, let's look at our demo_table again:\n",
    "\n",
    "If we want to select the third row of the Year column using bracket notation, our statement would appear as follows:\n",
    "\n",
    "> demo_table[3,\"Year\"]\n",
    "\n",
    "Because R keeps track of both the row indices as well as the column indices as integers under the hood, we can also select the same data using just number indices:\n",
    "\n",
    "> demo_table[3,3]\n",
    "\n",
    "There is a third way to select data from an R data frame that behaves very similarly to Pandas. By using the $ operator, we can select columns from any two-dimensional R data structure as a single vector, similar to selecting a series from a Pandas DataFrame. For example, if we want to select the vector of vehicle classes from demo_table, we would use the following statement:\n",
    "\n",
    "> demo_table$\"Vehicle_Class\"\n",
    "\n",
    "Once we have selected the single vector, we can use bracket notation to select a single value.\n",
    "\n",
    "> demo_table$\"Vehicle_Class\"[2]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Select Data with Logic\n",
    "\n",
    "Just as it is for selecting single values, there are multiple ways to subset and filter data from our larger data frames. As with most programming languages, we use a combination of operators and logical statements to tell R what data to filter. Thankfully, most operators are the same between R and Python, as shown below:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "One of the most common ways to filter and subset a dataset in R is to use bracket notation. To use bracket notation to filter a data frame, we can supply a logical statement to assert our row and columns.\n",
    "\n",
    "For example, if we want to filter our used car data demo_table2 so that we only have rows where the vehicle price is greater than $10,000, we would use the following statement:\n",
    "\n",
    "> filter_table <- demo_table2[demo_table2$price > 10000,]\n",
    "\n",
    "You might be wondering why a comma trails 10000. The comma is necessary to subset by rows. Adding column(s) after the comma specifies the columns to select.\n",
    "\n",
    "This filter statement generates a view-only data frame tab listing vehicles priced greater than $10,000, as shown in the following image:\n",
    "\n",
    "If you do not supply a logical statement to either rows or columns, R will default to returning all elements in that dimension.\n",
    "\n",
    "In this example, the demo_table2$price > 10000 logical statement creates a vector of TRUE/FALSE values that R uses to consider all rows that satisfy our logical statement.\n",
    "\n",
    "When our logical statements are simple (using only one or two operators), bracket notation is easy to read and write. However, if we need to filter and subset our data using more complicated logic, bracket notation can become cumbersome. In these cases, we'll use an R function such as subset() to filter our data."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Subset Data in R\n",
    "\n",
    "Another method to filter and subset data frames in R is to use the function subset(). Type the following code into the R console to look at the subset() documentation in the Help pane:\n",
    "\n",
    "> ?subset()\n",
    "\n",
    "The subset() function uses a few arguments to subset and filter a two-dimensional R data structure:\n",
    "\n",
    "x -  is the matrix, data frame, or tibble we wish to subset.\n",
    "\n",
    "subset -  contains the logical statements that determine which rows to keep.\n",
    "\n",
    "select - contains a logical statement, or list of column names to select from a data frame. If nothing is supplied, all columns will be returned.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For example, if we want to create a more elaborate filtered dataset from our used car data demo_table2 where price > 10000, drive == 4wd, and \"clean\" %in% title_status, we would use the following statement:\n",
    "\n",
    "> filter_table2 <- subset(demo_table2, price > 10000 & drive == \"4wd\" & \"clean\" %in% title_status) #filter by price and drivetrain\n",
    "\n",
    "When combining logical statements in R, use element-wise AND operator or element-wise OR operator.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this case, using subset() is cleaner than using brackets, which would look like this:\n",
    "\n",
    "> filter_table3 <- demo_table2[(\"clean\" %in% demo_table2$title_status) & (demo_table2$price > 10000) & (demo_table2$drive == \"4wd\"),]\n",
    "\n",
    "The subset() function makes filtering and subsetting easier to read by assuming column names in the subset argument, which cuts down on statement length. In almost all cases, the bracket notation and subset() function are functionally equivalent (especially when using logical statements) and interchangeable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sample Data in R\n",
    "\n",
    "Often in data science, we need to generate a random sample of data points from a larger dataset. For example, some models might take too long to run on a massive dataset and require a smaller sample of the data.\n",
    "\n",
    "Using filtering and subsetting methods may be appropriate for certain cases (such as looking at data within a specific timeframe), but usually we'll want to randomly sample our larger data to reduce bias. In these cases, we can use the built-in function sample(). Let's try it now.\n",
    "\n",
    "Type the following code into the R console to look at the sample() documentation in the Help pane:\n",
    "\n",
    "> ?sample()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The sample() function uses a few arguments to create a sampled vector from a larger vector:\n",
    "\n",
    "x - is the larger vector to select from.\n",
    "\n",
    "size - is the number of sample data points to select from x.\n",
    "\n",
    "replace - is a flag to tell whether or not it is okay to select the same values. By default, the argument is set to FALSE, which means each selected value is unique.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If we want to sample a large vector and create a smaller vector, we can set the vector to \"x\":\n",
    "\n",
    "> sample(c(\"cow\", \"deer\", \"pig\", \"chicken\", \"duck\", \"sheep\", \"dog\"), 4)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "When it comes to sampling a two-dimensional data structure, we need to supply the index of each row we want to sample. This process can be completed in three steps:\n",
    "\n",
    "1. Create a numerical vector that is the same length as the number of rows in the data frame using the colon (:) operator.\n",
    "\n",
    "2. Use the sample() function to sample a list of indices from our first vector.\n",
    "\n",
    "3. Use bracket notation to retrieve data frame rows from sample list."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "So, first capture the number of rows in demo_table in a variable. The nrow() function counts the number of rows in a dataframe.\n",
    "\n",
    "> num_rows <- 1:nrow(demo_table)\n",
    "\n",
    "Next, sample 3 of those rows, as shown in this code:\n",
    "\n",
    "> sample_rows <- sample(num_rows, 3)\n",
    "> ```\n",
    "\n",
    "Finally, retrieve the requested data within the demo_table:\n",
    "\n",
    "{.lang-r}\n",
    "\n",
    "demo_table[sample_rows,] ```\n",
    "\n",
    "If we want to combine all three steps in a single R statement, our code would be as follows:\n",
    "\n",
    "> demo_table[sample(1:nrow(demo_table), 3),]\n",
    "\n",
    "After we have successfully loaded in and selected our data, our next steps in analysis are to group, transform, and reshape our data as to prepare for visualizations and modeling."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "15.2.5 Transform, Group, and Reshape Data Using the Tidyverse Package\n",
    "\n",
    "One of the most successful optimized packages for R is the tidyverse (Links to an external site.) package. The tidyverse package contains libraries such as dplyr, tidyr, and ggplot2. These packages work together to help simplify the process of creating transformed data columns, grouping data using factors, reshaping our two-dimensional data structures, and visualizing our results using plots.\n",
    "\n",
    "Throughout this module and beyond, you'll find more and more uses for the tidyverse libraries as you become more comfortable with R and begin generating more complex and robust RScripts. For now, we'll concentrate on leveraging the tidyverse libraries to help us transform, group, and reshape our R data frames.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Transform\n",
    "\n",
    "Raw data is often insufficient in telling the full story. Usually when we are analyzing data, we want to perform calculations and incorporate the calculations back into the raw data to ease in downstream analysis. Tidyverse's dplyr (Links to an external site.) library transforms R data.\n",
    "\n",
    "The dplyr library contains a wide variety of functions that can be chained together to transform data quickly and easily. Using dplyr is slightly more complex than the simple assignment statement in R because dplyr allows the user to chain together functions in a single statement using their own pipe operator (%>%).\n",
    "\n",
    "By chaining functions together, the user does not need to assign intermediate vectors and tables. Instead, all of the data transformation can be performed in a single assignment function that is easy to read and interpret. To transform a data frame and include new calculated data columns, we'll use the mutate() function.\n",
    "\n",
    "Type the following code into the R console to look at the mutate() documentation in the Help pane:\n",
    "\n",
    "> library(tidyverse)\n",
    "> ?mutate()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The documentation for the mutate() function (generally any dplyr function) is a little obscure, but it makes more sense looking at the examples. We can think of the mutate() function as a series of smaller assignment statements that are separated by commas. Each of the assigned names appears as a new column in our raw data frame.\n",
    "\n",
    "For example, if we want to use our coworker vehicle data from the demo_table and add a column for the mileage per year, as well as label all vehicles as active, we would use the following statement:\n",
    "\n",
    "> demo_table <- demo_table %>% mutate(Mileage_per_Year=Total_Miles/(2020-Year),IsActive=TRUE) #add columns to original data frame"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For each name and expression, a new column is generated within our returned data frame. This returned data frame is then assigned to our original data structure demo_table.\n",
    "\n",
    "This process of mutating and transforming columns can be applied at any time (or even multiple times) within a dplyr pipe, and it can even reference columns that were generated from previous mutate() functions. These transformed data frames can be used in further downstream analysis, visualizations, and modeling. However, transformed data frames are not designed to summarize data. To summarize our data frames in R, we'll need to use a grouping function."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Group Data\n",
    "\n",
    "Just like in Python, grouping across a factor allows us to quickly summarize and characterize our dataset around a factor of interest (also known as a character vector in R, or list of strings in Python). The most straightforward way to perform a grouping on an R data frame is to use dplyr's group_by() function. The group_by() function tells dplyr which factor (or list of factors in order) to group our data frame by.\n",
    "\n",
    "The behavior of group_by() is almost identical to that of the Pandas DataFrame.groupby() function, with the exception of using a value or vector instead of a list. Once we have our group_by data structure, we use the dplyr summarize() function to create columns in our summary data frame.\n",
    "\n",
    "For example, if we want to group our used car data by the condition of the vehicle and determine the average mileage per condition, we would use the following dplyr statement:\n",
    "\n",
    "> summarize_demo <- demo_table2 %>% group_by(condition) %>% summarize(Mean_Mileage=mean(odometer), .groups = 'keep') #create summary table\n",
    "\n",
    "Dplyr's pipe operator allows us to move our connected functions to a new line while computing everything in the same assignment function. This allows you to write RScripts that are not too wide for your RScript window.\n",
    "\n",
    "Using the summarize() function is very similar to using the mutate() function on a raw data frame: for each name and summary function, we create a column in a summary data frame. Our simplest summary functions will use statistics summary functions such as mean(), median(), sd(), min(), max(), and n() (used to calculate the number of rows in each category)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "However, the dplyr summarize() documentation provides a more comprehensive list of functions that can be used to summarize our data. For example, if in addition to our previous summary table we wanted to add the maximum price for each condition, as well as add the vehicles in each category, our statement would look as follows:\n",
    "\n",
    "\n",
    "> summarize_demo <- demo_table2 %>% group_by(condition) %>% summarize(Mean_Mileage=mean(odometer),Maximum_Price=max(price),Num_Vehicles=n(), .groups = 'keep') #create summary table with multiple columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The summarize() function takes an additional argument, .groups. This allows you to control the the grouping of the result. The four possible values are:\n",
    "\n",
    ".groups = \"drop_last\" drops the last grouping level (default)\n",
    ".groups = \"drop\" drops all grouping levels and returns a tibble\n",
    ".groups = \"keep\" preserves the grouping of the input\n",
    ".groups = \"rowwise\" turns each row into its own group\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Reshape Data\n",
    "\n",
    "When performing more involved data analytics and visualizations, there may be situations where the shape and design of our data frame is overcomplicated or incompatible with the libraries and functions we wish to use. For example, a \"wide\" data frame with few rows and many columns and factors may be difficult to visualize. Or a \"long\" data frame may be difficult to analyze if it contains multiple rows for a single subject.\n",
    "\n",
    "Thankfully, the tidyr library from the tidyverse has the gather() and spread() functions to help reshape our data. The gather() function is used to transform a wide dataset into a long dataset.\n",
    "\n",
    "Type the following code into the R console to look at the gather() documentation in the Help pane:\n",
    "\n",
    "> ?gather()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To properly reshape an R data frame, the gather() function requires a few arguments:\n",
    "\n",
    "data -  is the data frame we wish to reshape. Instead of supplying the data frame object, we can alternatively use the pipe operator to create a dplyr/tidyr all-in-one statement.\n",
    "\n",
    "key - is the name of the variable column that the original, wider data frame will collapse into.\n",
    "\n",
    "value - is the name of the new value column derived from the original data frame results.\n",
    "\n",
    "… - represents a list of columns to collapse into the key column. If we do not supply a list of columns, all columns of the original data frame will be collapsed. If the columns are in order, we can use the colon (:) operator to create our list of columns to collapse.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "One of the easiest ways to learn how to reshape data is to practice with a simple dataset.\n",
    "\n",
    "For this example, first download the demo2.csv Once you have put the file in your active directory, load the demo2.csv file into your R environment and look at the top of the data frame:\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using the file Vehicle_data.xlsx, answer the following questions. \n",
    "\n",
    "1. Is the data in the “Vehicle Prices” tab in a long or wide format? - Long\n",
    "2. Is the data in the “Volkswagen 2020 Lineup” tab in a long or wide format? - Wide\n",
    "\n",
    "In wide format, categorical data is always grouped. You can think of it as a summary of long data. It is easier to read and interpret as compared to long format. In long vertical format, every row represents an observation belonging to a particular category."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The demo_table3 data frame contains survey results from 250 vehicles that were collected by a rental company. The rental company evaluated seven different metrics for each vehicle and rated each metric on a scale of 1 to 5, with 1 representing low and 5 representing high.\n",
    "\n",
    "This data would be considered a wide format because different metrics were collected from a single vehicle, and each metric (also known as a variable in this case) was stored as a separate column. To change this dataset to a long format, we would use gather() to reshape this dataset.\n",
    "\n",
    "Type the following function into the R console:\n",
    "\n",
    "> long_table <- gather(demo_table3,key=\"Metric\",value=\"Score\",buying_price:popularity)\n",
    "\n",
    "Alternatively, you may type the following function in the R console:\n",
    "\n",
    "> long_table <- demo_table3 %>% gather(key=\"Metric\",value=\"Score\",buying_price:popularity)\n",
    "\n",
    "\n",
    "By using the gather() function, we have collapsed all of the survey metrics into one Metric column and all of the values into a Score column. Because the Vehicle column was not in the arguments, it was treated as an identifier column and added to each row as a unique identifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Alternatively, if we have data that was collected or obtained in a long format, we can use tidyr's spread() function to spread out a variable column of multiple measurements into columns for each variable.\n",
    "\n",
    "Type the following code into the R console to look at the spread() documentation in the Help pane:\n",
    "\n",
    "> ?spread()\n",
    "\n",
    "To properly reshape an R data frame, the spread() function requires a few arguments:\n",
    "\n",
    "data - is the data frame we wish to reshape. Instead of supplying the data frame object, we can alternatively use the pipe operator to create a dplyr/tidyr all-in-one statement.\n",
    "\n",
    "key - is the name of the variable column that we wish to spread out.\n",
    "\n",
    "value - is the name of the value column that we wish to fill in our new variable columns with.\n",
    "\n",
    "fill - is an optional argument that will set any empty rows in a new variable column with the fill value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Therefore, if we want to spread out our previous long-format data frame back to its original format, we would use the following spread() statement:\n",
    "\n",
    "> wide_table <- long_table %>% spread(key=\"Metric\",value=\"Score\")\n",
    "\n",
    "And if we want to check if our newly created wide-format table is exactly the same as our original demo_table3, we can use R's all.equal() function:\n",
    "\n",
    "> all.equal(demo_table3, wide_table)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If you ever compare two data frames that you expect to be equal, and the all.equal() function tells you they're not, try sorting the columns of both data frames. You can sort columns using the order() and colnames()functions and bracket notation:\n",
    "\n",
    "> table <- table[,order(colnames(table))]\n",
    "\n",
    "(The comma in the bracket indicates that we're selecting all rows.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now that we have learned about selecting and manipulating our data in R, it's time to learn how to use R for data analysis. We'll begin by visualizing our datasets using ggplot2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
