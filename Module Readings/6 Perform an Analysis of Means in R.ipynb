{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "15.6.1 Sample Versus Population Dataset\n",
    "\n",
    "As part of his new job on the data analytics team, he'll have to perform retrospective analysis of historical vehicle data. This means Jeremy will have to know how to compare results and metrics across different groups and factors. Therefore, he needs to learn some statistical tests that will allow him to compare numerical variables."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In data analysis and statistics, an ideal dataset is one that contains measurements and results from every possible outcome, condition, or consideration. These datasets are known as a population dataset and contain all possible elements of a study or experiment.\n",
    "\n",
    "Often, such an exhaustive dataset is prohibitively expensive or logistically impossible to generate. In this case, we must use a sample or subset of the population dataset, where not all elements of a study or experiment are collected or measured.\n",
    "\n",
    "Since a sample dataset is just that—a sample—we must be clear about how a sample dataset represents the corresponding population data. One of the most straightforward ways to characterize a sample versus its population data is to compare the mean and standard deviation of both datasets. Ideally, a sample dataset will have a similar distribution to the population data, and therefore the mean and standard deviation would be about equal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To produce a sample dataset that has a similar distribution to the population data, most statisticians suggest using random sampling. \n",
    "\n",
    "Random sampling is a technique in data science in which every subject or data point has an equal chance of being included in the sample. This technique increases the likelihood that even a small sample size will include individuals from each \"group\" within the population.\n",
    "\n",
    "If performed using functions such as the built-in sample()function in R, or sample_n() function from dplyr, the resulting sample distributions should be similar to the input population data.\n",
    "\n",
    "When selecting sample data from a numerical vector, we should use the built-in sample() function. However, in most cases we will want to use the sample_n() function to select sample data from a two-dimensional data object."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Type the following code into the R console to look at the sample_n() documentation in the Help pane, listed under the subhead \"Usage\" in the image below:\n",
    "\n",
    ">?sample_n()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using the sample_n()function only requires two arguments:\n",
    "\n",
    "tbl is the name of the input table, which is typically the name of a data frame. Optionally, we can use a dplyr pipe (%>%) to provide the data frame object directly, in which case, this argument is optional.\n",
    "\n",
    "size is the number of rows to return. As noted in the documentation, if we are providing a data frame that was grouped using the group_by()function, the size argument is the number of groups to return.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To practice generating samples using random sampling, download the used vehicle dataset which contains market data on more than 300 used vehicles. If we want to visualize the distribution of driven miles for our entire population dataset, we can use the geom_density()function from ggplot2:\n",
    "\n",
    "> population_table <- read.csv('used_car_data.csv',check.names = F,stringsAsFactors = F) #import used car dataset\n",
    "> plt <- ggplot(population_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2\n",
    "> plt + geom_density() #visualize distribution using density plot\n",
    "\n",
    "In this example, we want to transform our miles driven using a log10 transformation. This is because the distribution of raw mileage is right skewed—a few used vehicles have more than 100,000 miles, while the majority of used vehicles have less than 50,000 miles. The log10 transformation makes our mileage data more normal."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now that we characterized our population data using our density plot, we'll create a sample dataset using dplyr's sample_n()function. Type the following code in the R console:\n",
    "\n",
    "> sample_table <- population_table %>% sample_n(50) #randomly sample 50 data points\n",
    "> plt <- ggplot(sample_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2\n",
    "> plt + geom_density() #visualize distribution using density plot"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "By using dplyr's sample_n() function, we can create a random sample dataset from our population data that contains minimal bias and (ideally) represents the population data.\n",
    "\n",
    "Depending on the size of the population data, we may need to also adjust the size argument in our sample_n() function to ensure that our sample data is representative of the underlying population data. There are two basic ways to check that our sample data is representative of the underlying population: a qualitative assessment of each density plot or a quantitative statistical test such as the one-sample t-test.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "15.6.2 Use the One-Sample t-Test\n",
    "\n",
    "The Student's t-test (most commonly referred to as t-test) is one of the most basic and popular statistical tests in the world. In statistics, we use a t-test to compare the mean of one dataset to another under a few assumptions.\n",
    "\n",
    "There are two main forms of the t-test that we use: the one-sample t-test and the two-sample t-test. \n",
    "\n",
    "The one-sample t-test is used to determine whether there is a statistical difference between the means of a sample dataset and a hypothesized, potential population dataset. In other words, a one-sample t-test is used to test the following hypotheses:\n",
    "\n",
    "H0 : There is no statistical difference between the observed sample mean and its presumed population mean.\n",
    "Ha : There is a statistical difference between the observed sample mean and its presumed population mean.\n",
    "\n",
    "We can also use a one-sided t-test by changing our alternative hypothesis to state that our sample mean is significantly less or significantly more than our presumed population mean."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Before we can apply any statistical test to our data, we must check if there are any assumptions regarding our input dataset. When it comes to our one-sample t-test there are five assumptions about our input data:\n",
    "\n",
    "1. The input data is numerical and continuous. This is because we are testing the distribution of two datasets.\n",
    "\n",
    "2. The sample data was selected randomly from its population data.\n",
    "\n",
    "3. The input data is considered to be normally distributed.\n",
    "\n",
    "4. The sample size is reasonably large. Generally speaking, this means that the sample data distribution should be similar to its population data distribution.\n",
    "\n",
    "5. The variance of the input data should be very similar.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As long as our input data satisfies (or mostly satisfies) the above assumptions, we can use the one-sample t-test to assert the similarities or differences in our data.\n",
    "\n",
    "In R, we can implement a one-sample t-test using the built-in stats package t.test()function. Type the following code into the R console to look at the t.test()documentation in the Help pane:\n",
    "\n",
    "> ?t.test()\n",
    "\n",
    "To use the t.test()function to perform our one-sample t-test, we have to use a few arguments:\n",
    "\n",
    "x - is the numeric vector of sample data.\n",
    "mu -  is the calculated mean of the population data.\n",
    "alternative - tells the t.test() function if the hypothesis is one-sided (one-tailed) or two-sided (two-tailed). The options for the alternative argument are “two.sided,” “less,” or “greater.” By default, the t.test() function assumes a two-sided t-test.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "By setting all three of these arguments, the t.test()function should produce our test statistic \"t\" along with our p-value, which we can use to evaluate our null hypothesis.\n",
    "\n",
    "For example, if we want to test if the miles driven from our previous sample dataset is statistically different from the miles driven in our population data, we would use our t.test()function as follows:\n",
    "\n",
    ">t.test(log10(sample_table$Miles_Driven),mu=mean(log10(population_table$Miles_Driven))) #compare sample versus population means\n",
    "\n",
    "One Sample t-test\n",
    "\n",
    "data:  log10(sample_table$Miles_Driven)\n",
    "t = -0.43891, df = 49, p-value = 0.6627\n",
    "alternative hypothesis: true mean is not equal to 4.39449\n",
    "95 percent confidence interval:\n",
    " 4.221537 4.505436\n",
    "sample estimates:\n",
    "mean of x \n",
    " 4.363487 \n",
    " \n",
    "There are a number of metrics produced from the t.test()function, but for now we will only concern ourselves with the calculated p-value. Assuming our significance level was the common 0.05 percent, our p-value is above our significance level. Therefore, we do not have sufficient evidence to reject the null hypothesis, and we would state that the two means are statistically similar.\n",
    "\n",
    "Due to random sampling, your sample dataset may differ from our example and thus your calculations may be different. Therefore, you'll need to compare your calculated p-value to your own significance level. If your p-value is lower than the significance level, you would have sufficient evidence to reject the null hypothesis and state that the two means are statistically different."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "15.6.3 Use the Two-Sample t-Test\n",
    "\n",
    "The second main form of the t-Test is a two-sample t-Test. Instead of testing whether a sample mean is statistically different from its population mean, the two-sample t-Test determines whether the means of two samples are statistically different. In other words, a two-sample t-Test is used to test the following hypotheses:\n",
    "\n",
    "H0 : There is no statistical difference between the two observed sample means.\n",
    "Ha : There is a statistical difference between the two observed sample means."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "There are also five assumptions regarding our input data when using the two-sample t-Test, which are the same as the one-sample t-Test:\n",
    "\n",
    "1. The input data is numerical and continuous.\n",
    "\n",
    "2. Each sample data was selected randomly from the population data.\n",
    "\n",
    "3. The input data is considered to be normally distributed.\n",
    "\n",
    "4. Each sample size is reasonably large. Generally speaking, this means that the sample data distribution should be similar to its population data distribution.\n",
    "\n",
    "5. The variance of the input data should be very similar."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In R, we use the same t.test() function to calculate both a one-sample t-Test and two-sample t-Test. However, the two-sample t-Test arguments are slightly different:\n",
    "\n",
    "- x is the first numeric vector of sample data.\n",
    "\n",
    "- y is the second numeric vector of sample data.\n",
    "\n",
    "- alternative tells the t.test() function if the hypothesis is one-sided (one-tailed) or two-sided (two-tailed). The options for the alternative argument are \"two.sided,\"\"less,\" or \"greater.\" By default, the t.test() function assumes a two-sided t-Test."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Once we have provided the necessary numeric vectors for each sample, the t.test() function will calculate our two-sample t-Test and return the same output as before. As practice, let's test whether the mean miles driven of two samples from our used car dataset are statistically different.\n",
    "\n",
    "First, we produce our two samples using the following R statements:\n",
    "\n",
    "> sample_table <- population_table %>% sample_n(50) #generate 50 randomly sampled data points\n",
    "> sample_table2 <- population_table %>% sample_n(50) #generate another 50 randomly sampled data points\n",
    "\n",
    "Because our samples should not contain bias, we would expect our null hypothesis to be true—our samples should not be statistically different. To confirm, we'll use the t.test() function as follows:\n",
    "\n",
    "> t.test(log10(sample_table$Miles_Driven),log10(sample_table2$Miles_Driven)) #compare means of two samples\n",
    "\n",
    "Welch Two Sample t-test\n",
    "\n",
    "data:  log10(sample_table$Miles_Driven) and log10(sample_table2$Miles_Driven)\n",
    "t = -1.6893, df = 79.092, p-value = 0.0951\n",
    "alternative hypothesis: true difference in means is not equal to 0\n",
    "95 percent confidence interval:\n",
    " -0.2967228  0.0242803\n",
    "sample estimates:\n",
    "mean of x mean of y \n",
    " 4.344331  4.480552 \n",
    "\n",
    "Assuming a significance level of 0.05 percent. Is there sufficient evidence to reject the null hypothesis of the two-sample t-test?\n",
    "\n",
    " The p-value is above the assumed significance level. Therefore, we would state that there is not enough evidence to reject the null hypothesis and we can confirm our two samples are not statistically different."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "15.6.4 Use the Two-Sample t-Test to Compare Samples\n",
    "\n",
    "In many cases, the two-sample t-test will be used to compare two samples from a single population dataset. However, two-sample t-tests are flexible and can be used for another purpose: to compare two samples, each from a different population. This is known as a pair t-test, because we pair observations in one dataset with observations in another. We use the pair t-test when:\n",
    "\n",
    "- Comparing measurements on the same subjects across a single span of time (e.g., fuel efficiency before and after an oil change)\n",
    "\n",
    "- Comparing different methods of measurement (e.g., testing tire pressure using two different tire pressure gauges)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The biggest difference between paired and unpaired t-tests is how the means are calculated. In an unpaired t-test, the means are calculated by adding up all observations in a dataset, and dividing by the number of data points. \n",
    "\n",
    "In a paired t-test, the means are determined from the difference between each paired observation. As a result of the new mean calculations, our paired t-test hypotheses will be slightly different:\n",
    "\n",
    "H0 : The difference between our paired observations (the true mean difference, or \"μd\") is equal to zero.\n",
    "Ha : The difference between our paired observations (the true mean difference, or \"μd\") is not equal to zero.\n",
    "\n",
    "When it comes to implementing a paired t-test in R, we'll use the t.test() function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The required arguments are slightly different from the unpaired two-sample t-test:\n",
    "\n",
    "- x is the first numeric vector of sample data.\n",
    "\n",
    "- y is the second numeric vector of sample data.\n",
    "\n",
    "- paired tells the t.test() function to perform a paired t-test. This value must be set to TRUE.\n",
    "\n",
    "- alternative tells the t.test() function if the hypothesis is one-sided (one-tailed) or two-sided (two-tailed). The options for the alternative argument are \"two.sided,\" \"less,\" or \"greater.\" By default, the t.test() function assumes a two-sided t-test."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To practice calculating a paired t-test in R, download the modified mpg dataset. The data file contains a modified version of R's built-in mpg dataset, where each 1999 vehicle was paired with a corresponding 2008 vehicle."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First, let's generate our two data samples using the following code:\n",
    "\n",
    "> mpg_data <- read.csv('mpg_modified.csv') #import dataset\n",
    "> mpg_1999 <- mpg_data %>% filter(year==1999) #select only data points where the year is 1999\n",
    "> mpg_2008 <- mpg_data %>% filter(year==2008) #select only data points where the year is 2008\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now that we have our paired datasets, we can use a paired t-test to determine if there is a statistical difference in overall highway fuel efficiency between vehicles manufactured in 1999 versus 2008. In other words, we are testing our null hypothesis—that the overall difference is zero. Using our t.test() function in R, our code would be as follows:\n",
    "\n",
    "> t.test(mpg_1999$hwy,mpg_2008$hwy,paired = T) #compare the mean difference between two samples\n",
    "\n",
    "Paired t-test\n",
    "\n",
    "data:  mpg_1999$hwy and mpg_2008$hwy\n",
    "t = -1.1165, df = 37, p-value = 0.2714\n",
    "alternative hypothesis: true difference in means is not equal to 0\n",
    "95 percent confidence interval:\n",
    " -2.1480860  0.6217702\n",
    "sample estimates:\n",
    "mean of the differences \n",
    "             -0.7631579 \n",
    "\n",
    "Assuming a significance level of 0.05 percent. Is there sufficient evidence to reject the null hypothesis of the paired t-test?\n",
    "\n",
    "Fail to reject the null hypothesis.\n",
    "\n",
    "The p-value is above the assumed significance level. Therefore, we would state that there is not enough evidence to reject the null hypothesis and there is no overall difference in fuel efficiency between vehicles manufactured in 1999 versus 2008."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "15.6.5 Use the ANOVA Test\n",
    "\n",
    "When dealing with large real-world numerical data, we're often interested in comparing the means across more than two samples or groups. The most straightforward way to do this is to use the analysis of variance (ANOVA) test, which is used to compare the means of a continuous numerical variable across a number of groups (or factors in R).\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Depending on your dataset and questions you wish to answer, an ANOVA can be used in multiple ways. For the purposes of this course, we'll concentrate on two different types of ANOVA tests:\n",
    "\n",
    "- A one-way ANOVA is used to test the means of a single dependent variable across a single independent variable with multiple groups. (e.g., fuel efficiency of different cars based on vehicle class).\n",
    "\n",
    "- A two-way ANOVA does the same thing, but for two different independent variables (e.g., vehicle braking distance based on weather conditions and transmission type)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Regardless of whichever type of ANOVA test we use, the statistical hypotheses of an ANOVA test are the same:\n",
    "\n",
    "H0 : The means of all groups are equal, or µ1 = µ2 = … = µn.\n",
    "\n",
    "Ha : At least one of the means is different from all other groups.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Additionally, both ANOVA tests have assumptions about the input data that must be validated prior to using the statistical test:\n",
    "\n",
    "The dependent variable is numerical and continuous, and the independent variables are categorical.\n",
    "The dependent variable is considered to be normally distributed.\n",
    "The variance among each group should be very similar.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In R, we can use the aov() function to perform both the one-way and two-way ANOVA test. Type the following code into the R console to look at the aov() documentation in the Help pane:\n",
    "\n",
    ">?aov()\n",
    "\n",
    "To perform an ANOVA test in R, we have to provide the aov()function two arguments:\n",
    "\n",
    "formula - is a special statement in R that tells the aov() function how to interpret the different variables and factors. In most cases, we’ll use the formula Y ~ A or Y ~ A + B where Y is the column name of the dependent variable, and A and B are the column names of the independent variables.\n",
    "\n",
    "data -  is the name of our input data frame. The data frame should contain columns for each variable.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Unlike the t.test() function, where each group was a separate numeric vector, the aov() function expects that all of the observations and grouping information are contained within a single data frame. \n",
    "\n",
    "Once we have our cleaned and labeled data frame, we're ready to perform our ANOVA test using the aov()function.\n",
    "\n",
    "To practice our one-way ANOVA, return to the mtcars dataset. For this statistical test, we'll answer the question, \"Is there any statistical difference in the horsepower of a vehicle based on its engine type?\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this case, we will use the \"hp\" and \"cyl\" columns from our mtcars dataset:\n",
    "\n",
    "- horsepower (the \"hp\" column) will be our dependent, measured variable\n",
    "number of cylinders (the \"cyl\" column) will be our independent, categorical variable.\n",
    "\n",
    "- However, in the mtcars dataset, the cyl is considered a numerical interval vector, not a categorical vector. Therefore, we must clean our data before we begin, using the following code:\n",
    "\n",
    "> mtcars_filt <- mtcars[,c(\"hp\",\"cyl\")] #filter columns from mtcars dataset\n",
    "> mtcars_filt$cyl <- factor(mtcars_filt$cyl) #convert numeric column to factor\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now that we have our cleaned dataset, we can use our aov()function as follows:\n",
    "\n",
    "> aov(hp ~ cyl,data=mtcars_filt) #compare means across multiple levels\n",
    "\n",
    "aov(formula = hp ~ cyl, data = mtcars_filt)\n",
    "\n",
    "Terms:\n",
    "                      cyl Residuals\n",
    "Sum of Squares  104030.54  41696.33\n",
    "Deg. of Freedom         2        29\n",
    "\n",
    "Residual standard error: 37.91839\n",
    "Estimated effects may be unbalanced"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Due to the fact that the ANOVA model is used in many forms, the initial output of our aov() function does not contain our p-values. To retrieve our p-values, we have to wrap our aov()function in a summary() function as follows:\n",
    "\n",
    "> summary(aov(hp ~ cyl,data=mtcars_filt))\n",
    "\n",
    "             Df Sum Sq Mean Sq F value   Pr(>F)    \n",
    "cyl          2 104031   52015   36.18 1.32e-08 ***\n",
    "Residuals   29  41696    1438                     \n",
    "---\n",
    "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
    "> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "When using the formula statement, each independent variable will be shown as a separate row, with an additional \"Residuals\" row that tells us what the residual error is for our ANOVA model. \n",
    "\n",
    "For our purposes, we are only concerned with the \"Pr(>F)\" column, which is the same as our p-value statistic.\n",
    "\n",
    "Depending on how small our p-value is, there may be symbols on the right side that indicate which significance level the p-value is below. \n",
    "\n",
    "In this case, our p-value is 1.32 ✕ 10^-8^, which is much smaller than our assumed 0.05 percent significance level. Therefore, we would state that there is sufficient evidence to reject the null hypothesis and accept that there is a significant difference in horsepower between at least one engine type and the others."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now that you have learned the differences between our t-tests and ANOVA tests, you're ready to analyze data and perform statistical tests when comparing means. Feel free to explore more datasets and practice implementing analysis of means on your own."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
